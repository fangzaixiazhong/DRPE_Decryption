import os
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
from PIL import Image
from unet_attention import UNetAttention
from unet import UNetDeep
import numpy as np

def ssim_loss(pred, target):
    C1 = 0.01 ** 2
    C2 = 0.03 ** 2

    mu_x = F.avg_pool2d(pred, 3, 1, 1)
    mu_y = F.avg_pool2d(target, 3, 1, 1)
    sigma_x = F.avg_pool2d(pred * pred, 3, 1, 1) - mu_x ** 2
    sigma_y = F.avg_pool2d(target * target, 3, 1, 1) - mu_y ** 2
    sigma_xy = F.avg_pool2d(pred * target, 3, 1, 1) - mu_x * mu_y

    ssim_map = ((2 * mu_x * mu_y + C1) * (2 * sigma_xy + C2)) / (
        (mu_x ** 2 + mu_y ** 2 + C1) * (sigma_x + sigma_y + C2)
    )
    return torch.clamp((1 - ssim_map.mean()) / 2, 0, 1)


class MixedLoss(nn.Module):
    def __init__(self, alpha=1):
        super(MixedLoss, self).__init__()
        self.alpha = alpha
        self.l1 = nn.L1Loss()

    def forward(self, pred, target):
        l1_loss = self.l1(pred, target)
        ssim_val = ssim_loss(pred, target)
        return self.alpha * l1_loss + (1 - self.alpha) * ssim_val


class DRPEDataset(Dataset):
    def __init__(self, raw_dir, encrypted_dir, folders, split="train", transform=None):

        self.image_pairs = []
        self.transform = transform

        assert split in ["train", "test"]
        self.split = split

        for folder in folders:
            raw_path = os.path.join(raw_dir, folder)
            enc_path = os.path.join(encrypted_dir, folder)
            if not os.path.exists(raw_path):
                continue

            files = sorted([
                f for f in os.listdir(raw_path)
                if f.endswith((".jpg", ".png"))
            ])

            if len(files) == 0:
                continue
            split_idx = int(0.8 * len(files))
            if self.split == "train":
                selected_files = files[:split_idx]
            else:
                selected_files = files[split_idx:]

            for file in selected_files:
                raw_img_path = os.path.join(raw_path, file)
                enc_img_name = file + "_mag.png"
                enc_img_path = os.path.join(enc_path, enc_img_name)

                if os.path.exists(enc_img_path):
                    self.image_pairs.append((enc_img_path, raw_img_path))

        print(f"{self.split} dataset initialized, total pairs: {len(self.image_pairs)}")

    def __len__(self):
        return len(self.image_pairs)

    def __getitem__(self, idx):
        enc_path, raw_path = self.image_pairs[idx]

        enc_img = Image.open(enc_path).convert("L")
        raw_img = Image.open(raw_path).convert("L")

        if self.transform:
            enc_img = self.transform(enc_img)
            raw_img = self.transform(raw_img)

        return enc_img, raw_img



if __name__ == "__main__":
    base_dir = r""
    raw_dir = os.path.join(base_dir, "grey")
    encrypted_dir = os.path.join(base_dir, "drpe_encrypted")
    fp = open('','a')
    fp.write("")
    from torchvision import transforms

    transform = transforms.Compose([
    transforms.Resize((128, 128)),     
    transforms.ToTensor(),              # [0,255] â†’ [0,1]
    transforms.Normalize(mean=(0.5,), std=(0.5,))  # â†’ [-1,1]
])

    all_folders = [
    f for f in os.listdir(raw_dir)
    if os.path.isdir(os.path.join(raw_dir, f))
]

    train_datasets = DRPEDataset(
    raw_dir=raw_dir,
    encrypted_dir=encrypted_dir,
    folders=all_folders,
    split="train",
    transform=transform
)

    test_datasets = DRPEDataset(
    raw_dir=raw_dir,
    encrypted_dir=encrypted_dir,
    folders=all_folders,
    split="test",
    transform=transform
)


    print("è®­ç»ƒæ–‡ä»¶å¤¹:", train_datasets)
    print("æµ‹è¯•æ–‡ä»¶å¤¹:", test_datasets)

    transform = transforms.Compose([
        transforms.Resize((128, 128)),
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])


    train_loader = DataLoader(
    train_datasets,
    batch_size=8,
    shuffle=True,
    num_workers=4,
    pin_memory=True
)

    test_loader = DataLoader(
    test_datasets,
    batch_size=8,
    shuffle=False,
    num_workers=4,
    pin_memory=True
)

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = UNetAttention().to(device)

    criterion = MixedLoss(alpha=1)
    optimizer = torch.optim.Adam(model.parameters(), lr=2e-4, weight_decay=1e-6)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=6, min_lr = 1e-7)
    #scheduler = torch.optim.lr_scheduler.StepLR(
    #optimizer,
    #step_size=16,
    #gamma=0.5
#)


    best_loss = float("inf")
    num_epochs = 256
    import datetime
    start_time = datetime.datetime.now()
    fp.write(f"=== è®­ç»ƒå¼€å§‹äº: {start_time.strftime('%Y-%m-%d %H:%M:%S')} ===\n")
    fp.write(f"è®­ç»ƒæ–‡ä»¶å¤¹: {train_datasets}\n")
    fp.write(f"æµ‹è¯•æ–‡ä»¶å¤¹: {test_datasets}\n")
    fp.write(f"è®¾å¤‡: {device}\n")
    fp.write(f"æ€»è½®æ¬¡: {num_epochs}\n")
    fp.write("=" * 50 + "\n")
    fp.flush()

    for epoch in range(num_epochs):
        epoch_start_time = datetime.datetime.now()  # è®°å½•æ¯è½®å¼€å§‹æ—¶é—´
        model.train()
        total_loss = 0

        for enc_img, raw_img in train_loader:
            enc_img, raw_img = enc_img.to(device), raw_img.to(device)

            # ğŸ”¹ éšæœºåŠ å…¥è½»å¾®å™ªå£°
            if np.random.rand() < 0.22:
                noise = torch.randn_like(enc_img) * 0.01
                enc_img = torch.clamp(enc_img + noise, -1, 1)

            outputs = model(enc_img)
            loss = criterion(outputs, raw_img)

            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        avg_loss = total_loss / len(train_loader)
        print(f"Epoch [{epoch+1}/{num_epochs}] - è®­ç»ƒæŸå¤±: {avg_loss:.6f}")


        model.eval()
        test_loss = 0
        with torch.no_grad():
            for enc_img, raw_img in test_loader:
                enc_img, raw_img = enc_img.to(device), raw_img.to(device)
                outputs = model(enc_img)
                loss = criterion(outputs, raw_img)
                test_loss += loss.item()
        avg_test_loss = test_loss / len(test_loader)
        print(f"â†’ æµ‹è¯•æŸå¤±: {avg_test_loss:.6f}\n")

        # ğŸ”» è°ƒæ•´å­¦ä¹ ç‡
        scheduler.step(avg_test_loss)
        #scheduler.step()

        current_lr = optimizer.param_groups[0]['lr']  # è·å–å½“å‰å­¦ä¹ ç‡

        # è®°å½•æœ¬è½®ç»“æœåˆ°æ—¥å¿—æ–‡ä»¶
        epoch_end_time = datetime.datetime.now()
        epoch_duration = (epoch_end_time - epoch_start_time).total_seconds()
        
        log_line = (f"Epoch {epoch+1:02d} | "
                   f"æ—¶é—´: {epoch_end_time.strftime('%H:%M:%S')} | "
                   f"è€—æ—¶: {epoch_duration:.1f}s | "
                   f"è®­ç»ƒæŸå¤±: {avg_loss:.6f} | "
                   f"æµ‹è¯•æŸå¤±: {avg_test_loss:.6f} | "
                   f"å­¦ä¹ ç‡: {current_lr:.2e}")
        
        fp.write(log_line + "\n")

        # ä¿å­˜æœ€ä¼˜æ¨¡å‹
        if avg_test_loss < best_loss:
            best_loss = avg_test_loss
            save_path = fr"./best_atten_unet_L1_n.pth"
            torch.save(model.state_dict(), save_path)
            print(f"æœ€ä¼˜æ¨¡å‹å·²æ›´æ–°å¹¶ä¿å­˜: {save_path}")
            fp.write(f"Epoch {epoch+1}: æœ€ä¼˜æ¨¡å‹å·²ä¿å­˜ (æµ‹è¯•æŸå¤±: {avg_test_loss:.6f})\n")

        # æ¯è½®å¤‡ä»½ä¸€æ¬¡
        if epoch%5==0:
            torch.save(model.state_dict(), fr"./ssim_epoch_{epoch+1}.pth")
        

        fp.flush()

    # è®°å½•è®­ç»ƒç»“æŸä¿¡æ¯
    end_time = datetime.datetime.now()
    total_duration = (end_time - start_time).total_seconds() / 60  # è½¬æ¢ä¸ºåˆ†é’Ÿ
    fp.write("=" * 50 + "\n")
    fp.write(f"=== è®­ç»ƒç»“æŸäº: {end_time.strftime('%Y-%m-%d %H:%M:%S')} ===\n")
    fp.write(f"æ€»è€—æ—¶: {total_duration:.1f} åˆ†é’Ÿ\n")
    fp.write(f"æœ€ä½³æµ‹è¯•æŸå¤±: {best_loss:.6f}\n")
    fp.write("=" * 50 + "\n\n")
    
    # å…³é—­æ—¥å¿—æ–‡ä»¶
    fp.close()
    
    print(f"è®­ç»ƒå®Œæˆï¼æœ€ä½³æµ‹è¯•æŸå¤±: {best_loss:.6f}")
    print(f"è¯¦ç»†æ—¥å¿—å·²ä¿å­˜")